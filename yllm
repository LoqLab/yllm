#!/bin/bash

# Default values
DEFAULT_MAX_TOKENS=4096
DEFAULT_TEMPERATURE=0.7
DEFAULT_TOP_P=0.7
DEFAULT_SEED=0
DEFAULT_MAX_COMPLETION_TOKENS=-1

# Initialize with defaults
YLLM_SEED=$DEFAULT_SEED
YLLM_MAX_COMPLETION_TOKENS=${DEFAULT_MAX_COMPLETION_TOKENS}
YLLM_MAX_TOKENS=$DEFAULT_MAX_TOKENS
YLLM_TEMPERATURE=$DEFAULT_TEMPERATURE
YLLM_TOP_P=$DEFAULT_TOP_P

# Function to reset variables to defaults
reset_to_defaults() {
    YLLM_MAX_TOKENS=$DEFAULT_MAX_TOKENS
    YLLM_TEMPERATURE=$DEFAULT_TEMPERATURE
    YLLM_TOP_P=$DEFAULT_TOP_P
    YLLM_SEED=$DEFAULT_SEED
    YLLM_MAX_COMPLETION_TOKENS=$DEFAULT_MAX_COMPLETION_TOKENS
    YLLM_MODEL=""
    YLLM_API_URL=""
    YLLM_API_KEY=""
    YLLM_EXTRA_CURL_FLAGS=""
    YLLM_ANTHROPIC_MODE=""
    YLLM_DEEPINFRA_MODE=""
    YLLM_COHERE_MODE=""
    YLLM_COHERE_WEB_MODE=""
}

# Function to get the config file path
get_config_file() {
    echo "$HOME/.yllm.conf"
}

# Function to read the default model from config
get_default_model() {
    local config_file=$(get_config_file)
    if [[ -f "$config_file" ]]; then
        source "$config_file"
        echo "$YLLM_DEFAULT_MODEL"
    fi
}

# Function to set the default model
set_default_model() {
    local model="$1"
    local config_file=$(get_config_file)
    echo "YLLM_DEFAULT_MODEL='$model'" > "$config_file"
}

# Function to clear the default model
clear_default_model() {
    local config_file=$(get_config_file)
    rm -f "$config_file"
}

# Function to check if Playwright is available
check_playwright() {
    if python3 -c "import playwright" &>/dev/null; then
        if [[ $YLLM_DEBUG ]]; then
            echo "Debug: Playwright is available" >&2
        fi
        return 0
    else
        if [[ $YLLM_DEBUG ]]; then
            echo "Debug: Playwright is not available" >&2
        fi
        return 1
    fi
}

# Function to scrape URL with Playwright
scrape_with_playwright() {
    local url="$1"
    python3 - << EOF
from playwright.sync_api import sync_playwright
import sys

with sync_playwright() as p:
    browser = p.chromium.launch(headless=True)
    page = browser.new_page()
    try:
        page.goto("$url")
        page.wait_for_selector('body')
        print(page.content())
    except Exception as e:
        print(f"Error: {str(e)}", file=sys.stderr)
    finally:
        browser.close()
EOF
}

# Function to mask API key
mask_api_key() {
    local key="$1"
    if [[ -n "$key" ]]; then
        # Show first 5 chars and last 3 chars with stars between
        local len=${#key}
        if [ $len -gt 8 ]; then
            echo "${key:0:5}****${key: -3}"
        else
            echo "${key:0:5}***" # For very short keys
        fi
    else
        echo ""
    fi
}

# Get default model info for help text
DEFAULT_MODEL=$(get_default_model)
if [[ -n "$DEFAULT_MODEL" ]]; then
    if [[ -f "$DEFAULT_MODEL" ]]; then
        source "$DEFAULT_MODEL"
    elif [[ -f "$HOME/.yllm/$DEFAULT_MODEL" ]]; then
        source "$HOME/.yllm/$DEFAULT_MODEL"
    fi
    DEFAULT_MODEL_TEXT="(current default: $DEFAULT_MODEL)"
else
    DEFAULT_MODEL_TEXT="(no default set)"
fi

# Mask the API key for display
MASKED_API_KEY=$(mask_api_key "$YLLM_API_KEY")

function print_help() {
  cat <<EOF
Usage: $0 [options] [--] [prompt]

Options:
  -h, --help                Print this help text and exit.
  -s, --settings <file>     Load YLLM_* env settings from the given file.
  -m, --model <model>       The model to use for the completion $DEFAULT_MODEL_TEXT
  -D, --set-default <model> Set the default model (name or path)
  -S, --show-default        Show the current default model
  -C, --clear-default       Clear the default model setting
  -a, --api-url <url>       The API URL to use (default: $YLLM_API_URL).
  -k, --api-key <key>       The API key to use (default: $MASKED_API_KEY).
  -t, --temperature <t      The temperature for the model (default: $TEMPERATURE).
  -p, --top-p <p>           The top-p value for the model (default: $TOP_P).
  -l, --max-tokens <n>      The maximum number of tokens to generate (default: $MAX_TOKENS).
  -c, --stdin               Read data from standard input.
  -u, --url <url>           Read text data from the given URL.
  -f, --file <file>         Read text data from the given file.
  -d, --dump-prompt         Write the prompt to stdout and exit.
  -r, --raw-stream          Show the raw JSONL stream from the API.
  -z, --just-save-it        Write inputs and outputs to hash-named file with prefix='./'
  -Z, --save-it-to <prefix> Write inputs and outputs to hash-named file with the given prefix.
  -P, --pdf-it              When saving, convert output to PDF and open it.
  -p, --pdf-it              When saving, convert output to PDF.
  -x, --debug               Show debug information including the curl command.

If no prompt is provided, read from standard input.
The prompt is built from input arguments in the order they are provided.
EOF
}

# Check if data is being piped in first
if [ ! -t 0 ]; then
    STDIN_CONTENT=$(cat)
    inputs+=("$STDIN_CONTENT")
fi

# no arguments, print help
if [[ $# -eq 0 ]]; then
  print_help
  exit 0
fi

# Parse command line arguments and flags
while [[ $# -gt 0 ]]; do
    case $1 in
        -h|--help)
            print_help
            exit 0
            ;;
        -s|--settings)
            SETTINGS_FILE="$2"
            reset_to_defaults
            # Check if the specified settings file exists in the current directory
            if [[ -f "$SETTINGS_FILE" ]]; then
                source "$SETTINGS_FILE"
            # If not found, check in the ~/.yllm directory
            elif [[ -f "$HOME/.yllm/$SETTINGS_FILE" ]]; then
                source "$HOME/.yllm/$SETTINGS_FILE"
            else
                echo "Settings file not found: $SETTINGS_FILE"
                exit 1
            fi
            shift # past argument
            shift # past value
            ;;
        -a|--api-url)
            YLLM_API_URL="$2"
            shift # past argument
            shift # past value
            ;;
        -k|--api-key)
            YLLM_API_KEY="$2"
            shift # past argument
            shift # past value
            ;;
        -m|--model)
            model="$2"
            reset_to_defaults
            # Check if the specified model exists as a file
            if [[ -f "$model" ]]; then
                source "$model"
            # If not found, check in the ~/.yllm directory
            elif [[ -f "$HOME/.yllm/$model" ]]; then
                source "$HOME/.yllm/$model"
            else
                echo "Model config not found: $model"
                exit 1
            fi
            shift # past argument
            shift # past value
            ;;
        -t|--temperature)
            YLLM_TEMPERATURE="$2"
            shift # past argument
            shift # past value
            ;;
        -p|--top-p)
            YLLM_TOP_P="$2"
            shift # past argument
            shift # past value
            ;;
        -l|--max-tokens)
            YLLM_MAX_TOKENS="$2"
            shift # past argument
            shift # past value
            ;;

        -c|--stdin)
            STDIN_CONTENT=$(cat)
            inputs+=("$STDIN_CONTENT")
            shift # past argument
            ;;
        -u|--url)
            url="$2"
            if [[ "$url" =~ \.pdf$ ]]; then
                # For PDF URLs, download to temp file and use pdftotext
                temp_pdf=$(mktemp)
                if curl -s -L "$url" -o "$temp_pdf"; then
                    URL_CONTENT="$(pdftotext "$temp_pdf" -)"
                    rm -f "$temp_pdf"
                else
                    echo "Error downloading PDF from URL" >&2
                    exit 1
                fi
            else
                # For non-PDF URLs, use playwright or regular scraping
                if check_playwright; then
                    URL_CONTENT="$(scrape_with_playwright "$2" | lynx -stdin -dump)"
                else
                    URL_CONTENT="$(curl -s "$2" | lynx -stdin -dump)"
                fi
            fi
            inputs+=("$URL_CONTENT")
            shift # past argument
            shift # past value
            ;;
        -f|--file)
            FILE="$2"
            mimetype=$(file -b --mime-type "$FILE")
            if [[ $mimetype == text/* ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "inode/symlink" ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "application/pdf" ]]; then
                FILE_CONTENT="$(pdftotext "$FILE" -)"
            elif [[ $mimetype == "application/json" ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "application/javascript" ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "application/x-ndjson" ]]; then
                FILE_CONTENT="$(cat "$FILE")"
            elif [[ $mimetype == "application/vnd.ms-excel" ]]; then
                FILE_CONTENT="$(ssconvert -T Gnumeric_stf:stf_csv "$FILE" fd://1)"
            elif [[ $mimetype == "application/epub+zip" ]] \
                || [[ $mimetype == "application/vnd.openxmlformats-officedocument.wordprocessingml.document" ]] \
                || [[ $mimetype == "application/msword" ]] \
                || [[ $mimetype == "application/postscript" ]]; then
                FILE_CONTENT="$(pandoc -s "$FILE" -t plain -o -)"
            else
                echo "Unsupported file type: $(file -b --mime-type "$FILE")"
                exit 1
            fi
            inputs+=("$FILE_CONTENT")
            shift # past argument
            shift # past value
            ;;
        -d|--dump-prompt)
            DUMP_PROMPT=1
            shift # past argument
            ;;
        -r|--raw-stream)
            RAW_STREAM=1
            shift # past argument
            ;;
        -z|--just-save-it)
            YLLM_SAVE_IT="./"
            shift # past argument
            ;;
        -Z|--save-it-to)
            YLLM_SAVE_IT="$2"
            shift # past argument
            shift # past argument
            ;;
        -P|--pdf-it)
            YLLM_PDF_IT=1
            YLLM_SAVE_IT="./"  # Automatically set save-it when pdf-it is used
            shift # past argument
            ;;
        -P|--pdf-it)
            YLLM_PDF_IT=1
            shift # past argument
            ;;
        -x|--debug)
            YLLM_DEBUG=1
            shift # past argument
            ;;
        -D|--set-default)
            set_default_model "$2"
            echo "Default model set to: $2"
            exit 0
            ;;
        -S|--show-default)
            default_model=$(get_default_model)
            if [[ -n "$default_model" ]]; then
                echo "Current default model: $default_model"
            else
                echo "No default model set"
            fi
            exit 0
            ;;
        -C|--clear-default)
            clear_default_model
            echo "Default model cleared"
            exit 0
            ;;
        *)
            inputs+=("$1")
            shift # past argument
            ;;
    esac
done

# if we should dump the prompt
if [[ $DUMP_PROMPT ]]; then
    printf "%s\n" "${inputs[@]}"
    exit 0
else

    # if no model has been specified, try to use default
    if [[ -z "$YLLM_MODEL" ]]; then
        default_model=$(get_default_model)
        if [[ -n "$default_model" ]]; then
            reset_to_defaults
            if [[ -f "$default_model" ]]; then
                source "$default_model"
            elif [[ -f "$HOME/.yllm/$default_model" ]]; then
                source "$HOME/.yllm/$default_model"
            else
                echo "Default model config not found: $default_model"
                exit 1
            fi
        else
            echo "No model specified. Please set the YLLM_MODEL environment variable, use the -m option, specify a config file, or set a default model."
            exit 1
        fi
    fi
fi

unbuffer="stdbuf -o0 -i0"

send_request() {
    prompt="$1"
    if [[ $YLLM_DEEPINFRA_MODE ]]; then
    prompt=$(echo "$prompt" | sed -e 's/\[INST\]//g' -e 's/\[\/INST\]//g')
    json_payload='{
        "input": '$prompt',
        "stream": true
    }'
    elif [[ $YLLM_COHERE_WEB_MODE ]]; then
    json_payload=$(printf '{
        "message": %s,
        "stream": true,
        "connectors": [{"id": "web-search"}],
        "temperature": %.2f,
        "max_tokens": %d,
        "top_p": %.2f
    }' "$prompt" $YLLM_TEMPERATURE $YLLM_MAX_TOKENS $YLLM_TOP_P)
    elif [[ $YLLM_COHERE_MODE ]]; then
    json_payload=$(printf '{
        "message": %s,
        "stream": true,
        "temperature": %.2f,
        "max_tokens": %d,
        "top_p": %.2f
    }' "$prompt" $YLLM_TEMPERATURE $YLLM_MAX_TOKENS $YLLM_TOP_P)
    elif [[ $YLLM_ANTHROPIC_MODE ]]; then
    json_payload=$(printf '{
            "messages": [
                {
                    "role": "user",
                    "content": %s
                }
            ],
            "model": "%s",
            "stream": true,
            "max_tokens": %d,
            "temperature": %.2f
        }' "$prompt" "$YLLM_MODEL" $YLLM_MAX_TOKENS $YLLM_TEMPERATURE)

    else
    if [[ $YLLM_API_URL == *"cerebras.ai"* ]]; then
        json_payload=$(printf '{
            "messages": [
                {
                    "role": "user",
                    "content": %s
                }
            ],
            "model": "%s",
            "stream": true,
            "temperature": %.2f,
            "max_completion_tokens": %d,
            "seed": %d,
            "top_p": %.2f
        }' "$prompt" "$YLLM_MODEL" $YLLM_TEMPERATURE $YLLM_MAX_COMPLETION_TOKENS $YLLM_SEED $YLLM_TOP_P)
    else
        json_payload=$(printf '{
            "messages": [
                {
                    "role": "user",
                    "content": %s
                }
            ],
            "model": "%s",
            "stream": true,
            "n": 1,
            "temperature": %.2f,
            "max_tokens": %d,
            "top_p": %.2f
        }' "$prompt" "$YLLM_MODEL" $YLLM_TEMPERATURE $YLLM_MAX_TOKENS $YLLM_TOP_P)
    fi
    fi

    json_payload=$(echo "$json_payload" | jq -c .)

    temp_file=$(mktemp)
    echo "$json_payload" > "$temp_file"

    cleanup() {
        [[ -n $temp_file && -f $temp_file ]] && rm -f "$temp_file"
    }

    trap cleanup EXIT

    auth_header="authorization: Bearer $YLLM_API_KEY"

    # if extra curl flags are set, use them, otherwise make the array empty
    if [[ -z $YLLM_EXTRA_CURL_FLAGS ]]; then
        YLLM_EXTRA_CURL_FLAGS=()
    else
        YLLM_EXTRA_CURL_FLAGS=($YLLM_EXTRA_CURL_FLAGS)
    fi
    if [[ $YLLM_ANTHROPIC_MODE ]]; then
      auth_header="x-api-key: $YLLM_API_KEY"
      YLLM_EXTRA_CURL_FLAGS=(-H 'anthropic-version: 2023-06-01')
    fi

    curl_cmd="curl --request POST \
         --silent \
         --url \"$YLLM_API_URL\" \
         -H 'content-Type: application/json' \
         -H \"$auth_header\" \
         ${YLLM_EXTRA_CURL_FLAGS[*]} \
         --data @\"$temp_file\""

    if [[ $YLLM_DEBUG ]]; then
        echo "Debug: Executing curl command:" >&2
        echo "$curl_cmd" >&2
        echo "Debug: Request payload:" >&2
        cat "$temp_file" >&2
        echo >&2
    fi

    $unbuffer curl --request POST \
         --silent \
         --url "$YLLM_API_URL" \
         -H 'content-Type: application/json' \
         -H "$auth_header" \
         "${YLLM_EXTRA_CURL_FLAGS[@]}" \
         --data @"$temp_file"
}

COMPLETE_PROMPT=$(printf "%s\n" "${inputs[@]}" | jq -sR .)

if [[ $RAW_STREAM ]]; then
    send_request "$COMPLETE_PROMPT"
    exit 0
fi

if [[ $YLLM_SAVE_IT ]]; then
    hash=$(echo -n "$COMPLETE_PROMPT" | sha256sum | awk '{print $1}' | head -c 8)
    output_file_base=$(mktemp ${YLLM_SAVE_IT}yllm_$hash.XXXXXX)
    rm -f "$output_file_base"
    output_file=$output_file_base.md
    output_raw=$output_file_base.jsonl
else
    output_file=/dev/null
    output_raw=/dev/null
fi

# PDF conversion will be done at the end after output is complete

# Send the request and extract the response
# do this if we're not in deepinfra mode
if [[ $YLLM_DEEPINFRA_MODE ]]; then
    send_request "$COMPLETE_PROMPT" \
    | $unbuffer sed 's%</s>"%"%' \
    | $unbuffer sed 's/^data: //g' | $unbuffer sed 's/\[DONE\]//' \
    | $unbuffer jq -j --unbuffered 'select(.token.text != null) | .token.text' \
    | tee $output_file
elif [[ $YLLM_ANTHROPIC_MODE ]]; then
  # we select content_block_delta
  send_request "$COMPLETE_PROMPT" \
      | $unbuffer grep '^data: ' \
      | $unbuffer grep 'content_block_delta' \
      | $unbuffer sed 's/^data: //g' \
      | $unbuffer jq -j --unbuffered '.delta.text' \
      | tee $output_file && echo
elif [[ $YLLM_COHERE_MODE ]]; then
    send_request "$COMPLETE_PROMPT" \
        | $unbuffer jq -j --unbuffered 'select(.event_type == "text-generation") | if .is_finished then "\n" else .text end' \
        | tee $output_file
elif [[ $YLLM_COHERE_WEB_MODE ]]; then
    send_request "$COMPLETE_PROMPT" \
        | tee $output_raw \
        | $unbuffer jq -j --unbuffered 'select(.event_type == "text-generation") | if .is_finished then "\n" else .text end' \
        | tee $output_file

    if [[ $YLLM_SAVE_IT ]]; then
        # Extract the documents and citations from the JSON record
    jq 'select(.event_type == "stream-end")' $output_raw >$output_raw.end
    (python3 - "$output_raw.end" <<'EOF'
import json
import sys

infile = sys.argv[1]

# Load the model output from a file
with open(infile, 'r') as file:
    record = json.load(file)

# Extract the main text, citations, and documents from the JSON record
main_text = record['response']['text']
citations = record['response']['citations']
documents = {doc['id']: doc for doc in record['response']['documents']}

# Initialize an empty string to hold the annotated text
annotated_text = ""
last_pos = 0  # Keep track of the last position processed

# Map from document ID to citation order
doc_id_to_order = {}
def get_set_id(my_dict, key):
    if key not in my_dict:
        my_dict[key] = len(my_dict) + 1
    return my_dict[key]

# Iterate over the citations
for citation in citations:
    # Add the text from the last position to the start of the current citation
    annotated_text += main_text[last_pos:citation['start']]
    
    # Add the citation text
    citation_text = main_text[citation['start']:citation['end']]
    annotated_text += citation_text

    # Prepare to add links
    links = []
    seen = set()
    
    # Construct the markdown links for each document in the citation
    for doc_id in citation['document_ids']:
        # Extract the document index from the ID and increment by 1 for natural numbering
        doc_index = doc_id.split('_')[-1].split(':')[0]
        doc_index = get_set_id(doc_id_to_order, doc_index)
        # Extract the actual URL for the document
        url = documents[doc_id]['url'] if doc_id in documents else "xxxxx"
        # Append the markdown link to the links list
        # (as long as it's not a duplicate URL)
        if url not in seen:
            links.append(f"[{doc_index}]({url})")
            seen.add(url)
    
    # Join all links with a comma and add them in a single set of brackets
    annotated_text += f" [{','.join(links)}]"
    
    # Update the last processed position
    last_pos = citation['end']

# Add any remaining text after the last citation
annotated_text += main_text[last_pos:]

# Print the annotated markdown text
print(annotated_text)
EOF
    ) > $output_file
    rm -f $output_raw.end
    fi
else
    send_request "$COMPLETE_PROMPT" \
    | $unbuffer sed 's%</s>"%"%' \
    | $unbuffer sed 's/^data: //g' | $unbuffer sed 's/\[DONE\]//' \
    | $unbuffer jq -j --unbuffered 'select(.choices[0].delta.content != null) | if .choices[0].finish_reason == "stop" then .choices[0].delta.content + "\n" else .choices[0].delta.content end' \
    | tee $output_file
    echo
fi

if [[ $YLLM_PDF_IT ]]; then
    # Wait a moment for file writes to complete
    sleep 0.5
    pandoc $output_file -o $output_file_base.pdf \
           --pdf-engine=xelatex -V mainfont="Liberation Sans" -V geometry:margin=1in \
           -V fontsize=12pt
    xdg-open $output_file_base.pdf &>/dev/null || \
    open $output_file_base.pdf &>/dev/null
fi
